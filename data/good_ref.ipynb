{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28214,
     "status": "ok",
     "timestamp": 1733374283872,
     "user": {
      "displayName": "An Dương Gia",
      "userId": "09855387270089562429"
     },
     "user_tz": -420
    },
    "id": "i20WfB6lqiUy",
    "outputId": "8860a0c6-92df-4371-b644-0575c792748a"
   },
   "outputs": [],
   "source": [
    "# NOTE: you CAN change this cell\n",
    "# If you want to use your own database, download it here\n",
    "#!gdown --fuzzy https://drive.google.com/file/d/16L9dKSmBEdA0Nl0ArRPWRr3TOCBxtolY/view?usp=sharing -O list_district.csv\n",
    "#!gdown --fuzzy https://drive.google.com/file/d/1mADlhA448KfCl_OUpfANiVDmAf6hqdpA/view?usp=sharing -O list_province.csv\n",
    "#!gdown --fuzzy https://drive.google.com/file/d/1lNAGhAeNscN1482mpPwIi4T2Vu6DdYBu/view?usp=sharing -O list_ward.csv\n",
    "# # # dummy text file\n",
    "# !gdown --fuzzy https://drive.google.com/file/d/1WaqZmJzBNlig-18TVqJLvZbypqjA0Gmc/view?usp=sharing -O list_district.txt\n",
    "# !gdown --fuzzy https://drive.google.com/file/d/1t5AZWb776UIAPC2b1YnajaQuoKQkJxZE/view?usp=sharing -O list_province.txt\n",
    "# !gdown --fuzzy https://drive.google.com/file/d/1P-8Y6yDR5o_PtimHltOf7RKUzhGESQ6z/view?usp=sharing -O list_ward.txt\n",
    "\n",
    "\n",
    "# private test text file\n",
    "#!gdown --fuzzy https://drive.google.com/file/d/1oSXQHLoVSGfBOLR4NjNwQRTkDb8Zd8OU/view?usp=sharing -O list_province.txt\n",
    "#!gdown --fuzzy https://drive.google.com/file/d/18sZoDAqJWyUfmjQN3VpKfkDHFQ-tcml6/view?usp=sharing -O list_district.txt\n",
    "#!gdown --fuzzy https://drive.google.com/file/d/1VfDCj7R11jf3SIZyoZdYL7fIN-AIhC-1/view?usp=sharing -O list_ward.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5861,
     "status": "ok",
     "timestamp": 1733374289729,
     "user": {
      "displayName": "An Dương Gia",
      "userId": "09855387270089562429"
     },
     "user_tz": -420
    },
    "id": "J8znFuZTzwoS",
    "outputId": "2907fbda-4e90-4dfb-db36-241e0a3d8765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
      "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.10/dist-packages (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "# NOTE: you CAN change this cell\n",
    "# Add more to your needs\n",
    "# you must place ALL pip install here\n",
    "!pip install numpy\n",
    "!pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AodaIxYa32hT"
   },
   "outputs": [],
   "source": [
    "# NOTE: you CAN change this cell\n",
    "# import your library here\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import signal\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xtwG3tBDzMLD"
   },
   "outputs": [],
   "source": [
    "# NOTE: you MUST change this cell\n",
    "# New methods / functions must be written under class Solution.\n",
    "\n",
    "\n",
    "\n",
    "class Solution:\n",
    "    def __init__(self):\n",
    "        # list provice, district, ward for private test, do not change for any reason\n",
    "        self.province_path = 'list_province.txt'\n",
    "        self.district_path = 'list_district.txt'\n",
    "        self.ward_path = 'list_ward.txt'\n",
    "\n",
    "        # write your preprocess here, add more method if needed\n",
    "        self.TIMEOUT = 0.1\n",
    "        self.province_path_internal = 'list_province.csv'\n",
    "        self.district_path_internal = 'list_district.csv'\n",
    "        self.ward_path_internal = 'list_ward.csv'\n",
    "        self.full_path_internal = 'list_full.csv'\n",
    "        self.prepare_database()\n",
    "\n",
    "    def clear_locations(self):\n",
    "        self.locations = {\n",
    "            \"province\": [],\n",
    "            \"district\": [],\n",
    "            \"ward\": [],\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "    def build_location_trie( self, path):\n",
    "\n",
    "        df = pd.read_csv(path)\n",
    "        data = df.to_dict(orient = 'records')\n",
    "\n",
    "        correct_trie = AddressTrie()\n",
    "        heuristics_trie = AddressTrie()\n",
    "        for loc_row in data:\n",
    "            loc_name = loc_row['name']\n",
    "            loc_normalized = normalize_text(loc_row['value'])\n",
    "            # full version correct spelling\n",
    "            full_word = remove_non_alphabet(remove_space(loc_normalized))\n",
    "            correct_trie.insert(word = full_word, raw = loc_name)\n",
    "            if loc_name.isdigit():\n",
    "                correct_trie.insert(word = loc_name, raw = loc_name)\n",
    "            # abbreviation version spelling\n",
    "            if not loc_name.isdigit():\n",
    "                word = ''.join([w[0] for w in  loc_normalized.split()])\n",
    "                if len(word)>1:\n",
    "                    correct_trie.insert(word = word, raw = loc_name )\n",
    "\n",
    "            word = ''.join([w[0] for w in  loc_normalized.split()[:-1]]) + loc_normalized.split()[-1]\n",
    "            if len(word)> 1:\n",
    "                correct_trie.insert(word = word, raw = loc_name)\n",
    "\n",
    "            for variant in gen_incorrect_version(full_word):\n",
    "                heuristics_trie.insert(word = variant, raw = loc_name)\n",
    "        return correct_trie, heuristics_trie\n",
    "\n",
    "    def build_address_combination_trie(self, path):\n",
    "        checklist_trie = AddressTrie()\n",
    "        df = pd.read_csv(path)\n",
    "        data = df.to_dict(orient= 'records')\n",
    "\n",
    "        for row in data:\n",
    "            city = row['city_name']\n",
    "            district = str(int(row['district_name'])) if row['district_name'].isdigit() else row['district_name']\n",
    "            ward =  str(int(row['ward_name'])) if row['ward_name'].isdigit() else row['ward_name']\n",
    "            # ward_district_province\n",
    "            word = (ward + district + city).replace(' ', '').lower()\n",
    "            checklist_trie.insert(word = word, raw = word )\n",
    "            # district + province\n",
    "            word = ( district + city).replace(' ', '').lower()\n",
    "            checklist_trie.insert(word = word, raw = word)\n",
    "            # ward + province\n",
    "            word = ( ward + city).replace(' ', '').lower()\n",
    "            checklist_trie.insert(word = word, raw = word )\n",
    "            # ward + district\n",
    "            word = (ward + district).replace(' ', '').lower()\n",
    "            checklist_trie.insert(word = word, raw = word)\n",
    "\n",
    "        return checklist_trie\n",
    "\n",
    "    def build_external_tries(self,):\n",
    "        p_trie = AddressTrie()\n",
    "        d_trie = AddressTrie()\n",
    "        w_trie = AddressTrie()\n",
    "        for row in read_txt_file(self.province_path):\n",
    "            p_trie.insert(word = row.replace(' ', '').lower(), raw = row)\n",
    "        for row in read_txt_file(self.district_path):\n",
    "            d_trie.insert(word = row.replace(' ', '').lower(), raw = row)\n",
    "        for row in read_txt_file(self.ward_path):\n",
    "            w_trie.insert(word = row.replace(' ', '').lower(), raw = row)\n",
    "        return p_trie, d_trie, w_trie\n",
    "\n",
    "\n",
    "    def prepare_database(self,):\n",
    "        self.province_trie, self.hprovince_trie = self.build_location_trie(self.province_path_internal)\n",
    "        self.district_trie, self.hdistrict_trie = self.build_location_trie(self.district_path_internal)\n",
    "        self.ward_trie, self.hward_trie= self.build_location_trie(self.ward_path_internal)\n",
    "        self.full_address_trie = self.build_address_combination_trie(self.full_path_internal)\n",
    "        self.external_province_trie, self.external_district_trie, self.external_ward_trie = self.build_external_tries()\n",
    "\n",
    "    def get_location(self, text, trie, is_exact = False ):\n",
    "        results = []\n",
    "        for item in generate_backward_ngrams(text, n = [4,3,2,1]):\n",
    "            chunk_index, chunk = item\n",
    "            temp = remove_non_alphabet(remove_space(normalize_text(chunk)))\n",
    "            current_search = trie.search(temp)\n",
    "            if current_search[0]:\n",
    "                results.append(\n",
    "                    MatchObject(\n",
    "                        start_index= chunk_index,\n",
    "                        end_index= chunk_index + len(chunk.split())  ,\n",
    "                        matched_text=chunk,\n",
    "                        prediction= current_search[1] ,\n",
    "                        is_exact= is_exact\n",
    "                        )\n",
    "                )\n",
    "        return results\n",
    "\n",
    "\n",
    "\n",
    "    def get_location_prediction_set(self, text,):\n",
    "        for loc in self.locations.keys():\n",
    "            self.locations[loc].extend(self.get_location(text, eval(f'self.{loc}_trie'), is_exact= True ))\n",
    "            self.locations[loc].extend(self.get_location(text, eval(f'self.h{loc}_trie')))\n",
    "        return self.locations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _process(self, s):\n",
    "        self.get_location_prediction_set(s)\n",
    "        final_guess = self.verify_prediction(self.locations, self.full_address_trie)\n",
    "        final_guess = self.check_prediction_with_db()\n",
    "        return final_guess\n",
    "\n",
    "    def verify_prediction(self, locations, full_address_trie):\n",
    "        max_score = -1\n",
    "        final_guess = None\n",
    "        p_matches = locations['province']  + [EMPTY_MATCH]\n",
    "        d_matches = locations['district']  + [EMPTY_MATCH]\n",
    "        w_matches = locations['ward']  + [EMPTY_MATCH]\n",
    "        for item in itertools.product(p_matches, d_matches, w_matches):\n",
    "            p_match = item[0]\n",
    "            d_match = item[1]\n",
    "            w_match = item[2]\n",
    "            combined_match = [w_match, d_match, p_match]\n",
    "            if is_valid_combination(combined_match):\n",
    "                p_guesses = p_match[-2]\n",
    "                d_guesses = d_match[-2]\n",
    "                w_guesses = w_match[-2]\n",
    "                for address_combination in itertools.product(w_guesses , d_guesses, p_guesses ):\n",
    "                        word = remove_space(''.join(address_combination) )\n",
    "                        if full_address_trie.contain(word.lower()):\n",
    "                            score = get_locations_score([p_match, d_match, w_match])\n",
    "                            if score > max_score:\n",
    "                                max_score = score\n",
    "                                final_guess = address_combination\n",
    "        self.locations = {\n",
    "            'province': final_guess[2] if final_guess is not None else '',\n",
    "            'district': final_guess[1] if final_guess is not None else '',\n",
    "            'ward': final_guess[0] if final_guess is not None else '',\n",
    "        }\n",
    "        return self.locations\n",
    "\n",
    "    def check_prediction_with_db(self):\n",
    "        for loc ,val in self.locations.items():\n",
    "            trie = eval(f'self.external_{loc}_trie')\n",
    "            val = val.replace(' ', '').lower()\n",
    "            if trie.contain(val):\n",
    "                self.locations[loc] =  trie.search(val)[1][0]\n",
    "            else:\n",
    "                self.locations[loc] =''\n",
    "\n",
    "        return self.locations\n",
    "\n",
    "    def return_result(self):\n",
    "\n",
    "        for key, value in self.locations.items():\n",
    "            if isinstance(value, str):\n",
    "                self.locations[key] = value\n",
    "            elif isinstance(value, list) and len(value) > 0 :\n",
    "                self.locations[key] = value[0][-2]\n",
    "            else:\n",
    "                self.locations[key] = ''\n",
    "\n",
    "        return self.locations\n",
    "\n",
    "\n",
    "    def process(self, s: str):\n",
    "        # write your process string here\n",
    "        signal.signal(signal.SIGALRM, timeout_handler)\n",
    "        signal.setitimer(signal.ITIMER_REAL,self.TIMEOUT)\n",
    "\n",
    "        try:\n",
    "            self.clear_locations()\n",
    "            s = preprocessing(s)\n",
    "            self._process(s)\n",
    "            return self.return_result()\n",
    "        except TimeoutException:\n",
    "          return self.return_result()\n",
    "        finally:\n",
    "          signal.setitimer(signal.ITIMER_REAL, 0)\n",
    "\n",
    "\n",
    "class MatchObject(NamedTuple):\n",
    "    start_index: int\n",
    "    end_index : int\n",
    "    matched_text: str\n",
    "    prediction: list\n",
    "    is_exact: bool\n",
    "\n",
    "EMPTY_MATCH= MatchObject(\n",
    "    start_index= -1,\n",
    "    end_index= -1,\n",
    "    matched_text= '',\n",
    "    prediction= [''],\n",
    "    is_exact= False\n",
    ")\n",
    "\n",
    "class TimeoutException(Exception):\n",
    "    pass\n",
    "def timeout_handler(signum, frame):\n",
    "    raise TimeoutException\n",
    "\n",
    "\n",
    "SEP = ','\n",
    "class AddressNode:\n",
    "    __slots__ = ['children', 'is_end', 'raw']  # Reduce per-instance memory usage\n",
    "\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.is_end = False\n",
    "        self.raw = []\n",
    "\n",
    "class AddressTrie:\n",
    "    def __init__(self):\n",
    "        self.root = AddressNode()\n",
    "        self.trie_count = 0\n",
    "\n",
    "    def insert(self,  word, raw):\n",
    "        node = self.root\n",
    "\n",
    "        for char in word:\n",
    "            if char not in node.children:\n",
    "                node.children[char]= AddressNode()\n",
    "            node = node.children[char]\n",
    "\n",
    "        node.is_end = True\n",
    "        if raw not in node.raw:\n",
    "            node.raw.append(raw)\n",
    "\n",
    "    def search(self, word):\n",
    "        node = self.root\n",
    "\n",
    "        for char in word:\n",
    "            if char not in node.children:\n",
    "                return False , None\n",
    "            node = node.children[char]\n",
    "\n",
    "        return node.is_end, node.raw\n",
    "\n",
    "    def contain(self, word):\n",
    "        node = self.root\n",
    "\n",
    "        for char in word:\n",
    "            if char not in node.children:\n",
    "                return False\n",
    "            node = node.children[char]\n",
    "\n",
    "        return node.is_end\n",
    "\n",
    "    def delete(self,word):\n",
    "        node = self.root\n",
    "\n",
    "        for char in word:\n",
    "            if char not in node.children:\n",
    "                return None # deleted word does not exits\n",
    "            node = node.children[char]\n",
    "\n",
    "        node.is_end = False\n",
    "\n",
    "    def search_longest(self, word):\n",
    "        node = self.root\n",
    "        last_match = None\n",
    "        last_match_len = 0\n",
    "\n",
    "        for i, char in enumerate(word):\n",
    "            if char not in node.children:\n",
    "                break\n",
    "            node = node.children[char]\n",
    "\n",
    "            if node.is_end:\n",
    "                last_match = node\n",
    "                last_match_len = i + 1\n",
    "        if last_match:\n",
    "            return word[:last_match_len], last_match.raw\n",
    "        return None , None\n",
    "\n",
    "    def traverse(self):\n",
    "        stack = [(self.root, '')]\n",
    "        while stack:\n",
    "            node, prefix = stack.pop()\n",
    "            if node.is_end:\n",
    "                yield prefix, node.raw\n",
    "            for char, child in reversed(node.children.items()):\n",
    "                stack.append((child, prefix + char))\n",
    "\n",
    "\n",
    "ALPHABET = 'abcdefghijklmnopqrstuvwxyz0123456789'\n",
    "\n",
    "def read_txt_file( path):\n",
    "    with open(path) as file:\n",
    "        for line in file.readlines():\n",
    "            yield line.strip()\n",
    "\n",
    "\n",
    "def get_locations_score(match_objects):\n",
    "    match_objects = [i for i in match_objects if i is not None ]\n",
    "    index_score = 0\n",
    "    len_score = 0\n",
    "    heuristics_score = 0\n",
    "    for item in match_objects:\n",
    "        index_score += item[0]\n",
    "        len_score  += len(item[2].split())\n",
    "        heuristics_score += 1 if item[-1] else 0\n",
    "\n",
    "    return index_score  + len_score * 2 +  heuristics_score\n",
    "\n",
    "def is_valid_combination(combined_match):\n",
    "    increasing_index = -1\n",
    "    left_end_index = - 1\n",
    "    for item in combined_match:\n",
    "        if item[0] == -1 :\n",
    "            continue\n",
    "        # increasing index\n",
    "        if item[0] >= increasing_index:\n",
    "            increasing_index = item[0]\n",
    "        else:\n",
    "            return False\n",
    "        # non overlapping section\n",
    "        if item[0] >= left_end_index:\n",
    "            left_end_index = item[1]\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def normalize_text( text: str) -> str:\n",
    "    # Remove diacritics and convert to lowercase\n",
    "    text = re.sub(r'[àáạảãâầấậẩẫăằắặẳẵ]', 'a', text.lower())\n",
    "    text = re.sub(r'[èéẹẻẽêềếệểễ]', 'e', text)\n",
    "    text = re.sub(r'[ìíịỉĩ]', 'i', text)\n",
    "    text = re.sub(r'[òóọỏõôồốộổỗơờớợởỡ]', 'o', text)\n",
    "    text = re.sub(r'[ùúụủũưừứựửữ]', 'u', text)\n",
    "    text = re.sub(r'[ỳýỵỷỹ]', 'y', text)\n",
    "    text = re.sub(r'đ', 'd', text)\n",
    "    return text\n",
    "\n",
    "def remove_consecutive_spaces(text):\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "def remove_space(text):\n",
    "    return text.replace(' ', '').strip()\n",
    "\n",
    "\n",
    "\n",
    "def loop_backward_ngram(text, n):\n",
    "    result = []\n",
    "    lst = text.split()\n",
    "    if len(lst) >=n:\n",
    "        for i in range(len(lst)-n, -1, -1):\n",
    "            result.append((i, ' '.join(lst[i:i+n])))\n",
    "        return result\n",
    "    return None\n",
    "\n",
    "\n",
    "def generate_backward_ngrams(text, n = [4, 3,2,1 ]):\n",
    "    ngrams = []\n",
    "    for i in n:\n",
    "        ngram = loop_backward_ngram(text, i)\n",
    "        if ngram:\n",
    "            ngrams.extend(ngram)\n",
    "    return ngrams\n",
    "\n",
    "\n",
    "def remove_non_alphabet(text, replacement = ''):\n",
    "    pattern = re.compile(r'[^a-z0-9 ]')\n",
    "    return pattern.sub(replacement, text)\n",
    "\n",
    "\n",
    "def remove_delimiter(text):\n",
    "    pattern = re.compile(r'[,-.]')\n",
    "    return pattern.sub(' ', text)\n",
    "\n",
    "def split_sticky_word(text: str) -> str:\n",
    "\n",
    "    words = text.split()\n",
    "    vietnamese_uppercase = r'[A-ZĐÁÀẢÃẠÂẤẦẨẪẬĂẮẰẲẴẶÉÈẺẼẸÊẾỀỂỄỆÍÌỈĨỊÓÒỎÕỌÔỐỒỔỖỘƠỚỜỞỠỢÚÙỦŨỤƯỨỪỬỮỰÝỲỶỸỴ]'\n",
    "\n",
    "    # Process each word\n",
    "    result = []\n",
    "    for word in words:\n",
    "        # Count uppercase letters in the word\n",
    "        uppercase_count = len(re.findall(vietnamese_uppercase, word))\n",
    "\n",
    "        if uppercase_count > 1:\n",
    "            # Split at uppercase letters, but keep the capital letter with its word\n",
    "            # Negative lookbehind (?<!^) ensures we don't split at the start of the word\n",
    "            # Negative lookbehind (?<![\\s]) ensures we don't split after an existing space\n",
    "            split_word = re.sub(rf'(?<!^)(?<![\\s])({vietnamese_uppercase})', r' \\1', word)\n",
    "            result.append(split_word)\n",
    "        else:\n",
    "            result.append(word)\n",
    "\n",
    "    return ' '.join(result)\n",
    "\n",
    "\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = resolve_abbreviations(text)\n",
    "    text = split_sticky_word(text)\n",
    "    text = remove_delimiter(text)\n",
    "    text  = remove_consecutive_spaces(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def gen_incorrect_version(word):\n",
    "    \"\"\"Generate variations with deduplication at generation time.\"\"\"\n",
    "    seen = set()  # Track seen variations\n",
    "\n",
    "    def safe_yield(item):\n",
    "        if item not in seen and item != word:\n",
    "            seen.add(item)\n",
    "            yield item\n",
    "\n",
    "    # Calculate length once\n",
    "    word_len = len(word)\n",
    "\n",
    "    if word_len >2 and word_len <20:\n",
    "        # Substitutions\n",
    "        for i in range(word_len):\n",
    "            current = word[i]\n",
    "            prefix = word[:i]\n",
    "            suffix = word[i+1:]\n",
    "            for c in ALPHABET:\n",
    "                if c != current:\n",
    "                    yield from safe_yield(prefix + c + suffix)\n",
    "\n",
    "        # Deletions\n",
    "        if word_len > 1:  # Only delete if word length > 1\n",
    "            for i in range(word_len):\n",
    "                yield from safe_yield(word[:i] + word[i+1:])\n",
    "\n",
    "        for i in range(word_len + 1):\n",
    "            prefix = word[:i]\n",
    "            suffix = word[i:]\n",
    "            for c in ALPHABET:\n",
    "                yield from safe_yield(prefix + c + suffix)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def resolve_abbreviations(text: str) -> str:\n",
    "\n",
    "    MAPPING = {\n",
    "        r'\\bXã': ' Xã ',\n",
    "        r'\\bHuyện': ' Huyện ',\n",
    "        r'\\btỉnh': ' tỉnh ',\n",
    "        r'\\bphố': ' phố ',\n",
    "        r'\\bT.T.H\\b': ' Thừa Thiên Huế ',\n",
    "        r'\\bThừa.t.Huế\\b': ' Thừa Thiên Huế ',\n",
    "        r'\\bT. Hải Dươnwg\\b': ' Hải Dương ',\n",
    "        r'\\bFHim\\b': 'Hìm',\n",
    "        r'\\bTin GJiang\\b': ' Tiền Giang ',\n",
    "        r'(\\d)(?!\\d)': r'\\1 ',\n",
    "        r'\\bPhường\\b': ' ',\n",
    "        r'\\bThị trấn\\b': ' ',\n",
    "        r'\\bQuận\\b': ' ',\n",
    "        r'\\bHuyện\\b': ' ',\n",
    "        r'\\bThị xã\\b': ' ',\n",
    "        r'\\bThành phố\\b': ' ',\n",
    "        r'\\bTỉnh\\b': ' ',\n",
    "        r'\\bkhu phố\\b': ' ',\n",
    "        r'\\btp\\.\\b': ' ',\n",
    "        r'\\bt\\.p\\b': ' ',\n",
    "        r'\\btp\\b': ' ',\n",
    "        r'0(?=[\\dA-Za-z])': ''\n",
    "    }\n",
    "\n",
    "    for pattern, replacement in MAPPING.items():\n",
    "        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
    "\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\s,', ',', text)\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55934,
     "status": "ok",
     "timestamp": 1733374350484,
     "user": {
      "displayName": "An Dương Gia",
      "userId": "09855387270089562429"
     },
     "user_tz": -420
    },
    "id": "hjO6FFcA0DYi",
    "outputId": "effe0971-1f63-4d86-8fc1-077e6d4d1593"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "TEAM_NAME = 'Group_22'\n",
      "EXCEL_FILE = 'Group_22.xlsx'\n",
      "   correct  total  score / 10  max_time_sec  avg_time_sec\n",
      "0     1277   1350        9.46        3.1815        0.0103\n",
      "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.10/dist-packages (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "# NOTE: DO NOT change this cell\n",
    "# This cell is for scoring\n",
    "\n",
    "TEAM_NAME = 'Group_22'  # This should be your team name\n",
    "EXCEL_FILE = f'{TEAM_NAME}.xlsx'\n",
    "\n",
    "import json\n",
    "import time\n",
    "with open(\"Pathoftestfile\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "summary_only = True\n",
    "df = []\n",
    "solution = Solution()\n",
    "timer = []\n",
    "correct = 0\n",
    "for test_idx, data_point in enumerate(data):\n",
    "    address = data_point[\"text\"]\n",
    "\n",
    "    ok = 0\n",
    "    try:\n",
    "        start = time.perf_counter_ns()\n",
    "        result = solution.process(address)\n",
    "        answer = data_point[\"result\"]\n",
    "        finish = time.perf_counter_ns()\n",
    "        timer.append(finish - start)\n",
    "        ok += int(answer[\"province\"] == result[\"province\"])\n",
    "        ok += int(answer[\"district\"] == result[\"district\"])\n",
    "        ok += int(answer[\"ward\"] == result[\"ward\"])\n",
    "        df.append([\n",
    "            test_idx,\n",
    "            address,\n",
    "            answer[\"province\"],\n",
    "            result[\"province\"],\n",
    "            int(answer[\"province\"] == result[\"province\"]),\n",
    "            answer[\"district\"],\n",
    "            result[\"district\"],\n",
    "            int(answer[\"district\"] == result[\"district\"]),\n",
    "            answer[\"ward\"],\n",
    "            result[\"ward\"],\n",
    "            int(answer[\"ward\"] == result[\"ward\"]),\n",
    "            ok,\n",
    "            timer[-1] / 1_000_000_000,\n",
    "        ])\n",
    "    except Exception as e:\n",
    "        df.append([\n",
    "            test_idx,\n",
    "            address,\n",
    "            answer[\"province\"],\n",
    "            \"EXCEPTION\",\n",
    "            0,\n",
    "            answer[\"district\"],\n",
    "            \"EXCEPTION\",\n",
    "            0,\n",
    "            answer[\"ward\"],\n",
    "            \"EXCEPTION\",\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "        ])\n",
    "        # any failure count as a zero correct\n",
    "        pass\n",
    "    correct += ok\n",
    "\n",
    "\n",
    "    if not summary_only:\n",
    "        # responsive stuff\n",
    "        print(f\"Test {test_idx:5d}/{len(data):5d}\")\n",
    "        print(f\"Correct: {ok}/3\")\n",
    "        print(f\"Time Executed: {timer[-1] / 1_000_000_000:.4f}\")\n",
    "\n",
    "\n",
    "print(f\"-\"*30)\n",
    "total = len(data) * 3\n",
    "score_scale_10 = round(correct / total * 10, 2)\n",
    "if len(timer) == 0:\n",
    "    timer = [0]\n",
    "max_time_sec = round(max(timer) / 1_000_000_000, 4)\n",
    "avg_time_sec = round((sum(timer) / len(timer)) / 1_000_000_000, 4)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "    [[correct, total, score_scale_10, max_time_sec, avg_time_sec]],\n",
    "    columns=['correct', 'total', 'score / 10', 'max_time_sec', 'avg_time_sec',],\n",
    ")\n",
    "\n",
    "columns = [\n",
    "    'ID',\n",
    "    'text',\n",
    "    'province',\n",
    "    'province_student',\n",
    "    'province_correct',\n",
    "    'district',\n",
    "    'district_student',\n",
    "    'district_correct',\n",
    "    'ward',\n",
    "    'ward_student',\n",
    "    'ward_correct',\n",
    "    'total_correct',\n",
    "    'time_sec',\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "df.columns = columns\n",
    "\n",
    "print(f'{TEAM_NAME = }')\n",
    "print(f'{EXCEL_FILE = }')\n",
    "print(df2)\n",
    "\n",
    "!pip install xlsxwriter\n",
    "writer = pd.ExcelWriter(EXCEL_FILE, engine='xlsxwriter')\n",
    "df2.to_excel(writer, index=False, sheet_name='summary')\n",
    "df.to_excel(writer, index=False, sheet_name='details')\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s5Wo0q0TMizM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1ht_M0QJ1QIQNN9coo2Po764EQ_anl3L8",
     "timestamp": 1733372468138
    },
    {
     "file_id": "1bjtcx6uET7VOB1FTOl67F-HN8RzrMHSq",
     "timestamp": 1731556346742
    },
    {
     "file_id": "1NyW5Qc0hWue9g-9oz36y-Gw4WrCiiPUl",
     "timestamp": 1730622037630
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
