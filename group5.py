# -*- coding: utf-8 -*-
"""Group5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jau6HNAYzIR5wggJ17ESWK75UCtr9VBO
"""

# NOTE: you CAN change this cell
# If you want to use your own database, download it here
# !gdown ...
# This link is public dataset
# !gdown --fuzzy https://drive.google.com/file/d/1oSXQHLoVSGfBOLR4NjNwQRTkDb8Zd8OU/view?usp=drive_link -O list_province.txt
# !gdown --fuzzy https://drive.google.com/file/d/18sZoDAqJWyUfmjQN3VpKfkDHFQ-tcml6/view?usp=drive_link -O list_district.txt
# !gdown --fuzzy https://drive.google.com/file/d/1VfDCj7R11jf3SIZyoZdYL7fIN-AIhC-1/view?usp=drive_link -O list_ward.txt
# #This link is group DB
# !gdown --fuzzy https://drive.google.com/file/d/1vO7nZFcCxc3gpyhz_1bBzSQqJtjkZxFy/view?usp=sharing -O list_full_address.csv
# !gdown --fuzzy https://drive.google.com/file/d/1KeWS9CM0OH9R8QeuycxYfo7bd3kLRj7m/view?usp=sharing -O autocorrect.py
# !gdown --fuzzy https://drive.google.com/file/d/1OsnMbIs8jBw4higApc60Ew68RXzgmFpE/view?usp=sharing -O trie.py
# !gdown --fuzzy https://drive.google.com/file/d/1ENkpx6zcz1_gytIxN0BRzsb_D8quh-na/view?usp=sharing -O utils.py

# NOTE: you CAN change this cell
# Add more to your needs
# you must place ALL pip install here
# !pip install editdistance

# NOTE: you CAN change this cell
# import your library here
from collections import defaultdict
from trie import PrefixTree
import utils as u
import autocorrect as ac
import pandas as pd
import re
import time

# NOTE: you MUST change this cell
# New methods / functions must be written under class Solution.
class Solution:
    def __init__(self):
        # list provice, district, ward for private test, do not change for any reason (these file will be provided later with this exact name)

        self.province_path = 'list_province.txt'
        self.district_path = 'list_district.txt'
        self.ward_path = 'list_ward.txt'

        # write your preprocess here, add more method if needed
        ward_db_path = 'list_ward.csv'
        district_db_path = 'list_district.csv'
        province_db_path = 'list_province.csv'
        full_location_db_path = 'list_full_address.csv'

        # self.ward_trie = self.initialize_trie(ward_db_path)
        # self.district_trie= self.initialize_trie(district_db_path)
        # self.province_trie = self.initialize_trie(province_db_path)
        self.province_trie = self.initialize_trie(self.province_path)
        self.district_trie= self.initialize_trie(self.district_path)
        self.ward_trie = self.initialize_ward_trie(self.ward_path)
        self.full_norm_location, self.full_district_location, self.location_full_dict, self.location_province_ward_dict, self.location_district_ward_dict = self.init_full_address(full_location_db_path)

        self.official_district_lst =[line for line in open(self.district_path).read().split('\n') if line.strip()]
        self.official_province_lst = [line for line in open(self.province_path).read().split('\n') if line.strip()]
        self.official_ward_lst = [line for line in open(self.ward_path).read().split('\n') if line.strip()]

        # self.save_trie_to_file(self.ward_trie, 'ward_trie.txt')
        # self.save_trie_to_file(self.district_trie, 'district_trie.txt')
        # self.save_trie_to_file(self.province_trie, 'province_trie.txt')


    def init_full_address(self, db_path):
        pd_data = pd.read_csv(db_path)
        data_list = pd_data.to_dict('records')

        location_district_dict = defaultdict(lambda: defaultdict(list))
        location_norm_dict = defaultdict(lambda: defaultdict(list))
        location_full_dict = defaultdict(lambda: defaultdict(list))
        location_province_ward_dict = defaultdict(list)
        location_district_ward_dict = defaultdict(list)
        for data in data_list:
            province = data['city_name']
            district = data['district_name']
            ward = data['ward_name']
            district_norm = self.remove_vietnamese_accents(self.lower(data['district_name']))
            district_norm = self.remove_space(district_norm)
            district_norm = self.remove_special_characters(district_norm)
            ward_norm = self.remove_vietnamese_accents(self.lower(data['ward_name']))
            ward_norm = self.remove_space(ward_norm)
            ward_norm = self.remove_special_characters(ward_norm)
            location_district_dict[province][district_norm] = district
            if ward_norm not in location_norm_dict[province][district_norm]:
                location_norm_dict[province][district_norm].append(ward_norm)
            location_full_dict[province][district].append(ward)
            location_province_ward_dict[province].append(ward)
            location_district_ward_dict[district].append(ward)

        location_norm_dict = {province: dict(districts) for province, districts in location_norm_dict.items()}
        location_district_dict = {province: dict(districts) for province, districts in location_district_dict.items()}
        location_full_dict = {province: dict(districts) for province, districts in location_full_dict.items()}
        return location_norm_dict, location_district_dict, location_full_dict, location_province_ward_dict, location_district_ward_dict

    def search(self, input_text, trie):
        return trie.search(input_text)

    def remove_vietnamese_accents(self,location):
        char_map = {v: k for k, values in Solution.CONVERT_VN_EN.items() for v in values}
        if not isinstance(location, str):  # Ensure it's a string
            return location  # Return unchanged if it's not a string
        else:
            return "".join(char_map.get(c, c) for c in location)

    def remove_special_characters(self,text: str) -> str:
        return re.sub(r'[^a-z0-9]', '', text)

    def create_abbreviation(self,name: str) -> str:
        words = name.split()
        if not words:
            return "", ""
        abbr_first = ''.join(word[0] for word in words)
        abbr_second = ''.join(word[0] for word in words[:-1]) + words[-1]
        return abbr_first, abbr_second

    def resolve_abbreviations(self, text: str) -> str:
        for pattern, replacement in Solution.MAPPING.items():
            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)

        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'\s,', ',', text)
        text = text.strip()

        return text

    def split_word(self, input_string):
        step1 = re.sub(r'(?<!^)(?=[A-Z])', ' ', input_string)
        step2 = re.sub(r'(?<=\D)(?=\d)', ' ', step1)
        step3 = re.sub(r'(?<=\d)(?=\D)', ' ', step2)

        return ' '.join(step3.split())

    def create_variations(self, word):
        variations = set()
        alphabet = Solution.ALPHANUMERIC  # Use the predefined alphanumeric set

        # Deletion: Remove one character at a time
        for i in range(len(word)):
            variations.add(word[:i] + word[i+1:])

        # Substitution: Replace each character with every letter in the alphabet
        for i in range(len(word)):
            for char in alphabet:
                if char != word[i]:  # Avoid replacing with the same character
                    variations.add(word[:i] + char + word[i+1:])

        # Insertion: Insert every letter of the alphabet at every position
        for i in range(len(word) + 1):
            for char in alphabet:
                variations.add(word[:i] + char + word[i:])

        return variations

    def initialize_ward_trie(self,data_path):
        # pd_data = pd.read_csv(data_path)
        # data_list = pd_data.to_dict('records')

        data_list = open(data_path).read().split('\n')
        data_list = [{"value": province, "name": province} for province in data_list]

        correctTrie = PrefixTree()
        """Initialize Trie"""
        for word in data_list:
            value = word['value']
            origin_word = word['name']
            value = self.pre_process(value)
            correctTrie.insert(value, origin_word)

            if not word['value'].isdigit():
                for false_value in self.create_variations(value):
                    correctTrie.insert(false_value, origin_word)
        return correctTrie

    def initialize_trie(self,data_path):
        # pd_data = pd.read_csv(data_path)
        # data_list = pd_data.to_dict('records')

        data_list = open(data_path).read().split('\n')
        data_list = [{"value": province, "name": province} for province in data_list]

        correctTrie = PrefixTree()
        """Initialize Trie"""
        for word in data_list:
            value = word['value']
            origin_word = word['name']
            value = self.pre_process(value)
            correctTrie.insert(value, origin_word)

            if not word['value'].isdigit():
                abbr1, abbr2 = self.create_abbreviation(word['value'])
                abbr2 = self.pre_process(abbr2)
                correctTrie.insert(abbr2, origin_word)

                abbr1 = self.pre_process(abbr1)
                correctTrie.insert(abbr1, origin_word)

                for false_value in self.create_variations(value):
                    correctTrie.insert(false_value, origin_word)
        return correctTrie

    def remove_space(self,word):
        return word.replace(" ", "")

    def lower(self,word):
        return word.lower()

    def reverse(self,word):
        return word[::-1]

    def pre_process(self,word):
        word = self.lower(word)
        word = u.remove_vietnamese_accents(word)
        word = self.remove_space(word)
        word = self.remove_special_characters(word)
        word = self.reverse(word)
        return word

    def search_province(self,input_str,used_time):
        """Search for a province in the trie."""
        if used_time > 0.09:
            return  "", 0
        max_len = min(len(input_str), 15)

        # input_text = u.process_input_string(input_text)
        # input_text = input_text[::-1]

        input_text = self.pre_process(input_str)

        true_word_lst = []
        search_text_lst = []

        city_time = time.time()
        for i in range(2, max_len):
            if (time.time() - city_time + used_time > 0.09):
                return "", 0

            search_text = input_text[:i]

            result, true_word = self.search(search_text,self.province_trie)
            if true_word is None:
                true_word = []
            elif len(true_word) == 1:
                true_word = true_word[0]
            else:
                best_true_word = ""
                min_score = 9999
                for t in true_word:
                    lower_true_word = self.remove_space(t.lower())
                    lower_input_str = self.remove_space(input_str.lower())
                    score = ac.min_edit_distance(lower_true_word[-i:], lower_input_str[-i:])
                    if score < min_score:
                        min_score = score
                        best_true_word = t
                true_word = best_true_word
            if result == True:
                true_word_lst.append(true_word)
                search_text_lst.append(search_text)
        if len(true_word_lst) > 0:
            best_true_word = ""
            min_score = 9999
            for candidate in set(true_word_lst):
                score = 0
                for part in search_text_lst:
                    # candidate = u.process_input_string(candidate)
                    # candidate = candidate[::-1]
                    score += ac.min_edit_distance(self.pre_process(candidate), part)
                if score < min_score:
                    min_score = score
                    best_true_word = candidate
                    len_true_word = len(part)
        else:
            best_true_word = ""
            len_true_word = 0

        if "-" in best_true_word:
            len_true_word += 3

        # print("best_true_word", best_true_word)
        # print("len_true_word", len_true_word)

        return best_true_word, len(best_true_word)

    def search_district(self,input_str,province,used_time):
        """Search for a district in the trie."""
        if used_time > 0.09:
            return  "", 0
        min_threshold = 0.29
        input_text = input_str.replace('Tnh', '').replace('Tinh', '').replace('tỉn', '').replace('Tỉn', '')
        input_text = self.resolve_abbreviations(input_text)
        input_text = self.lower(input_text)
        input_text = u.remove_vietnamese_accents(input_text)
        input_text = self.remove_space(input_text)
        input_text = self.remove_special_characters(input_text)

        max_len = min(len(input_text) + 1, 15 )

        district_time = time.time()
        if (province != ""):
            for i in range(1, max_len):
                if (time.time() - district_time + used_time > 0.5):
                    return False, "", 0

                search_text = input_text[-i:]
                if search_text == "":
                    continue

                for candidate in self.full_norm_location[province].keys():
                    if candidate in search_text and candidate.isdigit() == True:
                        if i + 1 <= len(input_text) and input_text[-i - 1].isdigit():
                            continue
                        return candidate, len(search_text)
                    score = ac.min_edit_distance(candidate, search_text)
                    if score < min_threshold*len(search_text):
                        if self.full_district_location[province][candidate] not in self.official_district_lst:
                            return "", 0
                        return self.full_district_location[province][candidate], len(self.full_district_location[province][candidate])
        else:
            input_text = self.pre_process(input_str)

            true_word_lst = []
            search_text_lst = []

            district_time = time.time()
            for i in range(1, max_len):
                if (time.time() - district_time + used_time > 0.09):
                    return "", 0

                search_text = input_text[:i]

                result, true_word = self.search(search_text,self.district_trie)
                if true_word is None:
                    true_word = []
                elif len(true_word) == 1:
                    true_word = true_word[0]
                else:
                    best_true_word = ""
                    min_score = 9999
                    for t in true_word:
                        lower_true_word = self.remove_space(t.lower())
                        lower_input_str = self.remove_space(input_str.lower())
                        score = ac.min_edit_distance(lower_true_word[-i:], lower_input_str[-i:])
                        if score < min_score:
                            min_score = score
                            best_true_word = t
                    true_word = best_true_word
                if result == True:
                    true_word_lst.append(true_word)
                    search_text_lst.append(search_text)
            if len(true_word_lst) > 0:
                best_true_word = ""
                min_score = 9999
                for candidate in set(true_word_lst):
                    score = 0
                    for part in search_text_lst:
                        score += ac.min_edit_distance(candidate, part)
                    if score < min_score:
                        min_score = score
                        best_true_word = candidate
                        len_true_word = len(part)
            else:
                best_true_word = ""
                len_true_word = 0

            # print("best_true_word", best_true_word)
            # print("len_true_word", len_true_word)

            return best_true_word, len_true_word

        return "", 0

    def search_ward(self,input_str,province,district,used_time,min_threshold = 0.29):
        results = []
        input_text = self.split_word(input_str)
        ward_time = time.time()
        best_len = 0
        for item in self.generate_backward_ngrams(input_text, n = [4,3,2,1]):
            if (time.time() - ward_time + used_time > 0.09):
                    return "", 0

            chunk_index, chunk = item
            temp = self.pre_process(chunk)
            result, origin_word = self.search(temp, self.ward_trie)
            if result:
                results.append(
                    {
                        "start_index": chunk_index,
                        "end_index": chunk_index + len(chunk.split()),
                        "matched_text": chunk,
                        "prediction": origin_word,
                        "is_exact": True
                    }
                )
        if not results:  
            return "", 0 
        
        if (province != "" and district != ""):
            min_score = 9999
            best_ward = ""
            for ward in results:
                if (time.time() - ward_time + used_time > 0.09):
                    return "", 0
                for _ward in ward["prediction"]:
                    if (time.time() - ward_time + used_time > 0.09):
                        return "", 0
                    if _ward not in self.location_full_dict[province][district]:
                        continue
                    score = ac.min_edit_distance(ward["matched_text"], _ward)
                    if score < min_score:
                        min_score = score
                        best_ward = _ward
            return best_ward, len(best_ward)

        elif (province != ""):
            min_score = 9999
            best_ward = ""
            for ward in results:
                if (time.time() - ward_time + used_time > 0.09):
                    return "", 0
                for _ward in ward["prediction"]:
                    if (time.time() - ward_time + used_time > 0.09):
                        return "", 0
                    if _ward not in self.location_province_ward_dict[province]:
                        continue
                    score = ac.min_edit_distance(ward["matched_text"], _ward)
                    if score < min_score:
                        min_score = score
                        best_ward = _ward
            return best_ward, len(best_ward)
        elif (district != ""):
            min_score = 9999
            best_ward = ""
            for ward in results:
                if (time.time() - ward_time + used_time > 0.09):
                    return "", 0
                for _ward in ward["prediction"]:
                    if (time.time() - ward_time + used_time > 0.09):
                        return "", 0
                    if _ward not in self.location_district_ward_dict[district]:
                        continue
                    score = ac.min_edit_distance(ward["matched_text"], _ward)
                    if score < min_score:
                        min_score = score
                        best_ward = _ward
            return best_ward, len(best_ward)
        else:
            min_score = 9999
            best_ward = ""
            for ward in results:
                if (time.time() - ward_time + used_time > 0.09):
                    return "", 0
                for _ward in ward["prediction"]:
                    if (time.time() - ward_time + used_time > 0.09):
                        return "", 0
                    score = ac.min_edit_distance(ward["matched_text"], _ward)
                    if score < len(ward["matched_text"].lower())*min_threshold:
                        min_score = score
                        best_ward = _ward
            return best_ward, len(best_ward)



    def loop_backward_ngram(self, text, n):
        result = []
        lst = text.split()
        if len(lst) >=n:
            for i in range(len(lst)-n, -1, -1):
                result.append((i, ' '.join(lst[i:i+n])))
            return result
        return None

    def generate_backward_ngrams(self, text, n = [4, 3,2,1 ]):
        ngrams = []
        for i in n:
            ngram = self.loop_backward_ngram(text, i)
            if ngram:
                ngrams.extend(ngram)
        return ngrams




    def process(self,input_string):

        """Process input string to extract address components."""
        start_time = time.time()

        # input_string = unicodedata.normalize("NFC", input_string)
        input_string = self.resolve_abbreviations(input_string)

        final_candidate, len_remove_province = self.search_province(input_string,used_time=time.time() - start_time)
        province = final_candidate

        new_input_string = input_string[:-len_remove_province] if len_remove_province > 0 else input_string
        final_candidate, len_remove_district = self.search_district(new_input_string, province, used_time=time.time() - start_time)
        district = final_candidate

        new_input_string = new_input_string[:-len_remove_district] if len_remove_district > 0 else new_input_string
        final_candidate, len_remove = self.search_ward(new_input_string, province, district, used_time=time.time() - start_time)
        ward = final_candidate

        if province not in self.official_province_lst:
            province = ""
        if district not in self.official_district_lst:
            district = ""
        if ward not in self.official_ward_lst:
            ward = ""

        address = {
            "ward": ward,
            "district": district,
            "province": province
        }

        # end_time = time.time()
        # execution_time = round(end_time - start_time, 6)

        return address


    CONVERT_VN_EN = {
        'e': ['e', 'é', 'è', 'ẽ', 'ẹ', 'ẻ', 'ê', 'ế', 'ề', 'ễ', 'ệ', 'ể'],
        'o': ['o', 'ó', 'ò', 'õ', 'ọ', 'ỏ', 'ô', 'ố', 'ồ', 'ỗ', 'ộ', 'ổ', 'ơ', 'ớ', 'ờ', 'ỡ', 'ợ', 'ở'],
        'i': ['i', 'í', 'ì', 'ĩ', 'ị', 'ỉ'],
        'y': ['y', 'ý', 'ỳ', 'ỹ', 'ỵ', 'ỷ'],
        'a': ['a', 'á', 'à', 'ã', 'ạ', 'ả', 'ă', 'ắ', 'ằ', 'ẵ', 'ặ', 'ẳ', 'â', 'ấ', 'ầ', 'ẫ', 'ậ', 'ẩ'],
        'u': ['u', 'ú', 'ù', 'ũ', 'ụ', 'ủ', 'ư', 'ứ', 'ừ', 'ữ', 'ự', 'ử'],
        'd': ['đ']
    }

    ALPHANUMERIC = "abcdefghijklmnopqrstuvwxyz0123456789"

    MAPPING = {
        r'\bXã': ' ',
        r'\bHuyện': ' ',
        r'\btỉnh': ' ',
        r'Tỉnwh\b': ' ',
        r'\bTỉnwh\b': ' ',
        r'\bTỉnwh': ' ',
        r'\bTP.HCM\b': ' Hồ Chí Minh ',
        r'\bTPHCM\b': ' Hồ Chí Minh ',
        r'\bT.P H.C.Minh\b': ' Hồ Chí Minh ',
        r'\bTP. HCM\b': ' Hồ Chí Minh ',
        r'\bT.T.H\b': ' Thừa Thiên Huế ',
        r'\bThừa.t.Huế\b': ' Thừa Thiên Huế ',
        r'\bT Quảyg Nm\b': ' Quảng Nam ',
        r'\bTQdung trị\b': ' Quảng Trị ',
        r'\bFHim\b': 'Hìm',
        r'\bTin GJiang\b': ' Tiền Giang ',
        r'\bT.Giang\b': ' Tiền Giang ',
        r'\bTGiang\b': ' Tiền Giang ',
        r'\bThành phố': ' ',
        r'\bthành phố': ' ',
        r'\bthành phô': ' ',
        r'\bThành phô': ' ',
        r'\bThành Phố': ' ',
        r'\bThành Phô': ' ',
        r'\bThành phố\b': ' ',
        r'\bPhường\b': ' ',
        r'\bThị trấn\b': ' ',
        r'\bQuận\b': ' ',
        r'\bHuyện\b': ' ',
        r'\bThị xã\b': ' ',
        r'\bTỉnh\b': ' ',
        r'\btỉnh\b': ' ',
        r'\bquận\b': ' ',
        r'\bhuyện\b': ' ',
        r'\bthị xã\b': ' ',
        r'\bphường\b': ' ',
        r'\bthị trấn\b': ' ',
        r'\btỉ,nh': ' ',
        r'\bt,ỉnh': ' ',
        r'\bxã\b': ' ',
        r'\bx,ã\b': ' ',
        r'\bx.ã\b': ' ',
        r'\bkhu phố\b': ' ',
        r'\bk.hu phố\b': ' ',
        r'\btp\.\b': ' ',
        r'\bt\.p\b': ' ',
        r'\btp\b': ' ',
    }

# NOTE: DO NOT change this cell
# This cell is for downloading private test
# !rm -rf test.json
# this link is public test
# !gdown --fuzzy https://drive.google.com/file/d/1PBt3U9I3EH885CDhcXspebyKI5Vw6uLB/view?usp=sharing -O test.json

# CORRECT TESTS
groups_province = {}
groups_district = {'hòa bình': ['Hoà Bình', 'Hòa Bình'], 'kbang': ['Kbang', 'KBang'], 'quy nhơn': ['Qui Nhơn', 'Quy Nhơn']}
groups_ward = {'ái nghĩa': ['ái Nghĩa', 'Ái Nghĩa'], 'ái quốc': ['ái Quốc', 'Ái Quốc'], 'ái thượng': ['ái Thượng', 'Ái Thượng'], 'ái tử': ['ái Tử', 'Ái Tử'], 'ấm hạ': ['ấm Hạ', 'Ấm Hạ'], 'an ấp': ['An ấp', 'An Ấp'], 'ẳng cang': ['ẳng Cang', 'Ẳng Cang'], 'ẳng nưa': ['ẳng Nưa', 'Ẳng Nưa'], 'ẳng tở': ['ẳng Tở', 'Ẳng Tở'], 'an hòa': ['An Hoà', 'An Hòa'], 'ayun': ['Ayun', 'AYun'], 'bắc ái': ['Bắc ái', 'Bắc Ái'], 'bảo ái': ['Bảo ái', 'Bảo Ái'], 'bình hòa': ['Bình Hoà', 'Bình Hòa'], 'châu ổ': ['Châu ổ', 'Châu Ổ'], 'chư á': ['Chư á', 'Chư Á'], 'chư rcăm': ['Chư Rcăm', 'Chư RCăm'], 'cộng hòa': ['Cộng Hoà', 'Cộng Hòa'], 'cò nòi': ['Cò  Nòi', 'Cò Nòi'], 'đại ân 2': ['Đại Ân  2', 'Đại Ân 2'], 'đak ơ': ['Đak ơ', 'Đak Ơ'], "đạ m'ri": ["Đạ M'ri", "Đạ M'Ri"], 'đông hòa': ['Đông Hoà', 'Đông Hòa'], 'đồng ích': ['Đồng ích', 'Đồng Ích'], 'hải châu i': ['Hải Châu  I', 'Hải Châu I'], 'hải hòa': ['Hải Hoà', 'Hải Hòa'], 'hành tín đông': ['Hành Tín  Đông', 'Hành Tín Đông'], 'hiệp hòa': ['Hiệp Hoà', 'Hiệp Hòa'], 'hòa bắc': ['Hoà Bắc', 'Hòa Bắc'], 'hòa bình': ['Hoà Bình', 'Hòa Bình'], 'hòa châu': ['Hoà Châu', 'Hòa Châu'], 'hòa hải': ['Hoà Hải', 'Hòa Hải'], 'hòa hiệp trung': ['Hoà Hiệp Trung', 'Hòa Hiệp Trung'], 'hòa liên': ['Hoà Liên', 'Hòa Liên'], 'hòa lộc': ['Hoà Lộc', 'Hòa Lộc'], 'hòa lợi': ['Hoà Lợi', 'Hòa Lợi'], 'hòa long': ['Hoà Long', 'Hòa Long'], 'hòa mạc': ['Hoà Mạc', 'Hòa Mạc'], 'hòa minh': ['Hoà Minh', 'Hòa Minh'], 'hòa mỹ': ['Hoà Mỹ', 'Hòa Mỹ'], 'hòa phát': ['Hoà Phát', 'Hòa Phát'], 'hòa phong': ['Hoà Phong', 'Hòa Phong'], 'hòa phú': ['Hoà Phú', 'Hòa Phú'], 'hòa phước': ['Hoà Phước', 'Hòa Phước'], 'hòa sơn': ['Hoà Sơn', 'Hòa Sơn'], 'hòa tân': ['Hoà Tân', 'Hòa Tân'], 'hòa thuận': ['Hoà Thuận', 'Hòa Thuận'], 'hòa tiến': ['Hoà Tiến', 'Hòa Tiến'], 'hòa trạch': ['Hoà Trạch', 'Hòa Trạch'], 'hòa vinh': ['Hoà Vinh', 'Hòa Vinh'], 'hương hòa': ['Hương Hoà', 'Hương Hòa'], 'ích hậu': ['ích Hậu', 'Ích Hậu'], 'ít ong': ['ít Ong', 'Ít Ong'], 'khánh hòa': ['Khánh Hoà', 'Khánh Hòa'], 'krông á': ['Krông Á', 'KRông á'], 'lộc hòa': ['Lộc Hoà', 'Lộc Hòa'], 'minh hòa': ['Minh Hoà', 'Minh Hòa'], 'mường ải': ['Mường ải', 'Mường Ải'], 'mường ẳng': ['Mường ẳng', 'Mường Ẳng'], 'nậm ét': ['Nậm ét', 'Nậm Ét'], 'nam hòa': ['Nam Hoà', 'Nam Hòa'], 'na ư': ['Na ư', 'Na Ư'], 'ngã sáu': ['Ngã sáu', 'Ngã Sáu'], 'nghi hòa': ['Nghi Hoà', 'Nghi Hòa'], 'nguyễn úy': ['Nguyễn Uý', 'Nguyễn úy', 'Nguyễn Úy'], 'nhân hòa': ['Nhân Hoà', 'Nhân Hòa'], 'nhơn hòa': ['Nhơn Hoà', 'Nhơn Hòa'], 'nhơn nghĩa a': ['Nhơn nghĩa A', 'Nhơn Nghĩa A'], 'phúc ứng': ['Phúc ứng', 'Phúc Ứng'], 'phước hòa': ['Phước Hoà', 'Phước Hòa'], 'sơn hóa': ['Sơn Hoá', 'Sơn Hóa'], 'tạ an khương đông': ['Tạ An Khương  Đông', 'Tạ An Khương Đông'], 'tạ an khương nam': ['Tạ An Khương  Nam', 'Tạ An Khương Nam'], 'tăng hòa': ['Tăng Hoà', 'Tăng Hòa'], 'tân hòa': ['Tân Hoà', 'Tân Hòa'], 'tân hòa thành': ['Tân Hòa  Thành', 'Tân Hòa Thành'], 'tân khánh trung': ['Tân  Khánh Trung', 'Tân Khánh Trung'], 'tân lợi': ['Tân lợi', 'Tân Lợi'], 'thái hòa': ['Thái Hoà', 'Thái Hòa'], 'thiết ống': ['Thiết ống', 'Thiết Ống'], 'thuận hòa': ['Thuận Hoà', 'Thuận Hòa'], 'thượng ấm': ['Thượng ấm', 'Thượng Ấm'], 'thụy hương': ['Thuỵ Hương', 'Thụy Hương'], 'thủy xuân': ['Thuỷ Xuân', 'Thủy Xuân'], 'tịnh ấn đông': ['Tịnh ấn Đông', 'Tịnh Ấn Đông'], 'tịnh ấn tây': ['Tịnh ấn Tây', 'Tịnh Ấn Tây'], 'triệu ái': ['Triệu ái', 'Triệu Ái'], 'triệu ẩu': ['Triệu ẩu', 'Triệu Ẩu'], 'trung hòa': ['Trung Hoà', 'Trung Hòa'], 'trung ý': ['Trung ý', 'Trung Ý'], 'tùng ảnh': ['Tùng ảnh', 'Tùng Ảnh'], 'úc kỳ': ['úc Kỳ', 'Úc Kỳ'], 'ứng hòe': ['ứng Hoè', 'Ứng Hoè'], 'vĩnh hòa': ['Vĩnh Hoà', 'Vĩnh Hòa'], 'vũ hòa': ['Vũ Hoà', 'Vũ Hòa'], 'xuân ái': ['Xuân ái', 'Xuân Ái'], 'xuân áng': ['Xuân áng', 'Xuân Áng'], 'xuân hòa': ['Xuân Hoà', 'Xuân Hòa'], 'xuất hóa': ['Xuất Hoá', 'Xuất Hóa'], 'ỷ la': ['ỷ La', 'Ỷ La']}
groups_ward.update({1: ['1', '01'], 2: ['2', '02'], 3: ['3', '03'], 4: ['4', '04'], 5: ['5', '05'], 6: ['6', '06'], 7: ['7', '07'], 8: ['8', '08'], 9: ['9', '09']})
def to_same(groups):
    same = {ele: k for k, v in groups.items() for ele in v}
    return same
same_province = to_same(groups_province)
same_district = to_same(groups_district)
same_ward = to_same(groups_ward)
def normalize(text, same_dict):
    return same_dict.get(text, text)

TEAM_NAME = 'Group_5'  # This should be your team name
EXCEL_FILE = f'{TEAM_NAME}.xlsx'

import json
import time
with open('test.json') as f:
    data = json.load(f)

summary_only = True
df = []
solution = Solution()
timer = []
correct = 0
for test_idx, data_point in enumerate(data):
    address = data_point["text"]

    ok = 0
    try:
        answer = data_point["result"]
        answer["province_normalized"] = normalize(answer["province"], same_province)
        answer["district_normalized"] = normalize(answer["district"], same_district)
        answer["ward_normalized"] = normalize(answer["ward"], same_ward)

        start = time.perf_counter_ns()
        result = solution.process(address)
        finish = time.perf_counter_ns()
        timer.append(finish - start)
        result["province_normalized"] = normalize(result["province"], same_province)
        result["district_normalized"] = normalize(result["district"], same_district)
        result["ward_normalized"] = normalize(result["ward"], same_ward)

        province_correct = int(answer["province_normalized"] == result["province_normalized"])
        district_correct = int(answer["district_normalized"] == result["district_normalized"])
        ward_correct = int(answer["ward_normalized"] == result["ward_normalized"])
        ok = province_correct + district_correct + ward_correct

        df.append([
            test_idx,
            address,
            answer["province"],
            result["province"],
            answer["province_normalized"],
            result["province_normalized"],
            province_correct,
            answer["district"],
            result["district"],
            answer["district_normalized"],
            result["district_normalized"],
            district_correct,
            answer["ward"],
            result["ward"],
            answer["ward_normalized"],
            result["ward_normalized"],
            ward_correct,
            ok,
            timer[-1] / 1_000_000_000,
        ])
    except Exception as e:
        print(f"{address}")
        print(f"{answer = }")
        print(f"{result = }")
        df.append([
            test_idx,
            address,
            answer["province"],
            "EXCEPTION",
            answer["province_normalized"],
            "EXCEPTION",
            0,
            answer["district"],
            "EXCEPTION",
            answer["district_normalized"],
            "EXCEPTION",
            0,
            answer["ward"],
            "EXCEPTION",
            answer["ward_normalized"],
            "EXCEPTION",
            0,
            0,
            0,
        ])
        # any failure count as a zero correct
        pass
    correct += ok


    if not summary_only:
        # responsive stuff
        print(f"Test {test_idx:5d}/{len(data):5d}")
        print(f"Correct: {ok}/3")
        print(f"Time Executed: {timer[-1] / 1_000_000_000:.4f}")


print(f"-"*30)
total = len(data) * 3
score_scale_10 = round(correct / total * 10, 2)
if len(timer) == 0:
    timer = [0]
max_time_sec = round(max(timer) / 1_000_000_000, 4)
avg_time_sec = round((sum(timer) / len(timer)) / 1_000_000_000, 4)

import pandas as pd

df2 = pd.DataFrame(
    [[correct, total, score_scale_10, max_time_sec, avg_time_sec]],
    columns=['correct', 'total', 'score / 10', 'max_time_sec', 'avg_time_sec',],
)

columns = [
    'ID',
    'text',
    'province',
    'province_student',
    'province_normalized',
    'province_student_normalized',
    'province_correct',
    'district',
    'district_student',
    'district_normalized',
    'district_student_normalized',
    'district_correct',
    'ward',
    'ward_student',
    'ward_normalized',
    'ward_student_normalized',
    'ward_correct',
    'total_correct',
    'time_sec',
]

df = pd.DataFrame(df)
df.columns = columns

print(f'{TEAM_NAME = }')
print(f'{EXCEL_FILE = }')
print(df2)

import xlsxwriter

# !pip install xlsxwriter
writer = pd.ExcelWriter(EXCEL_FILE, engine='xlsxwriter')
df2.to_excel(writer, index=False, sheet_name='summary')
df.to_excel(writer, index=False, sheet_name='details')
writer.close()